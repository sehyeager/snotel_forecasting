{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "closed-greek",
   "metadata": {},
   "source": [
    "# Combining dfs and making dfs for basins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-ghana",
   "metadata": {},
   "source": [
    "### Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "maritime-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "shaped-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = pd.read_csv('sams_clean_data.csv')\n",
    "kat = pd.read_csv('basin_2000_2010.csv')\n",
    "grant = pd.read_csv('90s-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "distinguished-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('./basin_csvs')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-glenn",
   "metadata": {},
   "source": [
    "### Making all the columns the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spatial-torture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam.columns == kat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "desirable-major",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YYYYMMDD', 'lat', 'long', 'basin_name', 'station_id', 'acton_id',\n",
       "       'station_name', 'elevation', 'wteq_amt', 'wteq_med', 'wteq_amt_pct_med',\n",
       "       'prec_wytd_amt', 'prec_wytd_avg', 'prec_wytd_pctavg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geological-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(grant['basin_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "competitive-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "grant = pd.concat([grant, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "novel-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "grant.drop('basin_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lasting-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "grant.columns = grant.columns.str.lower()\n",
    "kat.columns = kat.columns.str.lower()\n",
    "sam.columns = sam.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "diagnostic-pilot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant.columns == sam.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-librarian",
   "metadata": {},
   "source": [
    "### Making seperate dfs for each basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "appointed-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first combine all our dfs\n",
    "df = pd.concat([sam, grant, kat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "systematic-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('allyears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "phantom-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(\",\",'').str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tutorial-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_names = df.drop(['yyyymmdd', 'lat', 'long', 'station_id', 'acton_id', 'station_name',\n",
    "                       'elevation', 'wteq_amt', 'wteq_med', 'wteq_amt_pct_med',\n",
    "                       'prec_wytd_amt', 'prec_wytd_avg', 'prec_wytd_pctavg'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acting-trading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['big_and_little_lost_basins', 'big_and_little_wood_basins',\n",
       "       'bitterroot', 'chelan_entiat_wenatchee', 'clearwater_and_salmon',\n",
       "       'columbia_above_methow', 'deschutes_crooked_john_day',\n",
       "       'flathead_river_basin', 'grand_ronde_powder_burnt_imnaha',\n",
       "       'henrys_fork_teton_willow_blackfoot_portneuf', 'idaho_panhandle_region',\n",
       "       'kootenai_river_in_montana', 'lewis_cowlitz',\n",
       "       'lower_clark_fork_river_basin', 'lower_columbia_hood_river',\n",
       "       'owyhee_malheur', 'raft_goose_salmon_falls_bruneau',\n",
       "       'snake_above_palisades', 'umatilla_walla_walla_willow',\n",
       "       'upper_clark_fork_river_basin', 'weiser_payette_boise',\n",
       "       'white_green_cedar_skykomish_snoqualmi_baker_skagit', 'willamette',\n",
       "       'yakima_ahtanum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basin_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-repository",
   "metadata": {},
   "source": [
    "#### Function for seperating out basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prepared-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(basin):\n",
    "    l = []\n",
    "    sub_df = df[df[basin] == 1]\n",
    "    l.append(sub_df)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "trying-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_dict = {}\n",
    "for name in basin_names:\n",
    "    basin_dict[name] = make_list(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "spread-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in basin_dict:\n",
    "    basin_df = basin_dict[key][0]\n",
    "    basin_df.reset_index(drop=True, inplace=True)\n",
    "    basin_df.to_csv(f'./basin_csvs/{key}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-wallace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
